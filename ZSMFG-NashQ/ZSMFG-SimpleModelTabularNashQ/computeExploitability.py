import numpy as np
from tqdm import tqdm
from myEnv import my1dGridEnv
from myTable import myQTable
from NashQLearner import NashQPlayer

def compute_exploitability(steps,Players,Q_1,Q_2,pi_1,pi_2,env):
    r_t_1 = []
    r_t_2 = []

    r_t_1.append(Players.value_iterations(Q_1,Q_2,pi_2,env,steps))
    r_t_2.append(Players.value_iterations(Q_2,Q_1,pi_1,env,steps))


    
    return  r_t_1,r_t_2

env = my1dGridEnv()
file = np.load("ZSMFG-NashQ/historyTables/Q_MC_ones_results_iter1000.npz")
Q_1 = file["Q_1"]
Q_2 = file["Q_2"]
            
if __name__=="__main__":
    for i in range(len(Q_1)):
        print(Q_1[i])
    
    # Players = NashQPlayer(env,Q_1_table=myQTable(history_table=Q_1),Q_2_table = myQTable(history_table=Q_2))
    # pi_1,pi_2,reward_1,reward_2 = Players.recover_equilibrium_policy(10,Q_1=Players.Q_1,Q_2=Players.Q_2,env=env)
    # explo_value_1,explo_value_2=compute_exploitability(100,Players,Q_1,Q_2,pi_1,pi_2,env)
    # np.savez("ZSMFG-NashQ/ZSMFG-SimpleModelTabularNashQ/policies&exploitability/random_pi_explo", 
    # pi_1=pi_1,pi_2=pi_2,explo_1=explo_value_1,explo_2=explo_value_2,steps=100)
